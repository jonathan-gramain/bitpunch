#!/usr/bin/env python

import pytest

from bitpunch import model
import conftest

#
# Test LevelDB formats
#
# log format:
# https://github.com/google/leveldb/blob/master/doc/log_format.md
#
# One interesting characteristic is that blocks are fixed-sized 32KB,
# except the last block which can be truncated. This forces the browse
# code to skip to the tail block whenever there is less than 32KB to
# read from the file.
#
# Otherwise it's a pretty straightforward format.
#

@pytest.fixture
def spec_log():
    fmt = """
type u8 byte: integer(signed=false);
type u16 byte[2]: integer(signed=false, endian=little);
type u32 byte[4]: integer(signed=false, endian=little);

file {
    LogBlock[] head_blocks;
    LogTailBlock tail_block;
}

struct LogBlock {
    Record[] records;
    byte[] trailer;
    span 32768;
};

struct LogTailBlock {
    Record[] records;
};

struct Record {
    u32 checksum;
    u16 length;
    u8 rtype;
    byte[length] data: string;
};
"""

    return model.FormatSpec(fmt)


@pytest.fixture
def data_log_empty():
    return conftest.to_bytes("""
    """)

@pytest.fixture
def data_log_small():
    # Log file generated by the "level" CLI tool after putting two
    # key/value pairs
    return conftest.to_bytes("""
    1b cc 27 c2 21 00 01
    01 00 00 00 00 00 00 00 01 00 00 00 01
    09 '"coolkey"' 09 'coolvalue'
    95 c4 c2 6e 27 00 01 02
    00 00 00 00 00 00 00 01  00 00 00 01
    0c '"coolnewkey"' 0c 'coolnewvalue'
    """)

@pytest.fixture
def data_log_multiblock():
    # create a 43 bytes record
    record = conftest.to_bytes("""
    1b cc 27 c2 24 00 01
    01 00 00 00 00 00 00 00 01 00 00 00 01
    09 '"coolkey!"' 09 'coolvalue!!'
    """)

    #43 * 762 == 32766: add 2 padding bytes before next block begins
    return (record * 762
            + conftest.to_bytes('00 00')
            + record * 3)


def test_leveldb_log_browse(spec_log, data_log_empty, data_log_small):
    inputs = [data_log_empty, data_log_small]
    for data in inputs:
        dtree = model.DataTree(data, spec_log)
        block_count = 0
        for block in dtree.head_blocks:
            block_count += 1
            record_count = 0
            for record in block.records:
                record_count += 1
            assert record_count == len(block.records)
        assert block_count == len(dtree.head_blocks)

        block = dtree.tail_block
        record_count = 0
        for record in block.records:
            record_count += 1
        assert record_count == len(block.records)


def test_leveldb_log_empty(spec_log, data_log_empty):
    dtree = model.DataTree(data_log_empty, spec_log)
    assert model.make_python_object(dtree.head_blocks) == []
    assert model.make_python_object(dtree.tail_block.records) == []
    assert len(dtree.head_blocks) == 0
    assert len(dtree.tail_block.records) == 0

    assert model.eval('sizeof(head_blocks)', dtree) == 0
    assert model.eval('sizeof(tail_block.records)', dtree) == 0

    with pytest.raises(IndexError):
        dtree.tail_block.records[0]

    with pytest.raises(ValueError):
        model.eval('tail_block.records[0]', dtree)


def test_leveldb_log_small(spec_log, data_log_small):
    dtree = model.DataTree(data_log_small, spec_log)
    assert model.make_python_object(dtree.head_blocks) == []
    records = dtree.tail_block.records
    assert len(records) == 2

    assert records[0].checksum == 0xC227CC1B
    assert records[0].length == 33
    assert records[0].rtype == 1
    assert len(records[0].data) == 33
    assert model.eval('sizeof(tail_block.records[0])', dtree) == 40

    assert records[1].checksum == 0x6EC2C495
    assert records[1].length == 39
    assert records[1].rtype == 1
    assert len(records[1].data) == 39
    assert model.eval('sizeof(tail_block.records[1])', dtree) == 46

    assert model.eval('sizeof(tail_block.records)', dtree) == 86
    assert model.eval('sizeof(tail_block)', dtree) == 86

    with pytest.raises(IndexError):
        dummy = records[2]

    with pytest.raises(ValueError):
        model.eval('tail_block.records[2]', dtree)


def test_leveldb_log_multiblock(spec_log, data_log_multiblock):
    dtree = model.DataTree(data_log_multiblock, spec_log)
    assert len(dtree.head_blocks) == 1
    assert len(dtree.head_blocks[0].records) == 762
    assert len(dtree.tail_block.records) == 3
    assert model.eval('sizeof(head_blocks)', dtree) == 32768
    assert model.eval('sizeof(head_blocks[0])', dtree) == 32768
    assert model.eval('sizeof(head_blocks[0].records)', dtree) == 32766
    assert model.eval('sizeof(head_blocks[0].trailer)', dtree) == 2
    assert model.make_python_object(
        model.eval('head_blocks[0].trailer', dtree)) == '\x00\x00'
    assert model.eval('sizeof(tail_block.records)', dtree) == 43 * 3

    records = dtree.head_blocks[0].records
    dummy = records[761]
    with pytest.raises(IndexError):
        dummy = records[762]



#
# SST index block
#

@pytest.fixture
def spec_sst_index():
    return """
    type u32 byte[4]: integer(signed=false, endian=little);

    type VarInt byte[]: varint();

    struct BlockHandle {
        VarInt offset;
        VarInt size;
    };

    struct IndexEntry {
        VarInt key_shared_size;
        VarInt key_non_shared_size;
        VarInt value_size;
        byte[key_non_shared_size] key_non_shared;
        byte[value_size] value;
        ?data_block => value: BlockHandle;
    };

    file {
        IndexEntry[] entries;
        u32[nb_restarts] restarts;
        u32 nb_restarts;
    }
    """

@pytest.fixture
def data_sst_index_block_1():
    return {
        'data': conftest.load_test_dat(__file__, 'sst_index_block_1.dat'),
        'nb_entries': 237
    }


def test_sst_index_block(spec_sst_index,
                         data_sst_index_block_1):
    data, nb_entries = (data_sst_index_block_1['data'],
                        data_sst_index_block_1['nb_entries'])
    dtree = model.DataTree(data, spec_sst_index)
    assert len(dtree.entries) == nb_entries
    last_index = None
    for i, entry in enumerate(dtree.entries):
        last_index = i
        model.make_python_object(entry)
    assert last_index == nb_entries - 1
    assert len(dtree.restarts) == dtree.nb_restarts
    assert model.get_size(dtree.restarts) == dtree.nb_restarts * 4
